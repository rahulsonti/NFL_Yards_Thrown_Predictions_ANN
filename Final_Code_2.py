# -*- coding: utf-8 -*-
"""OR603_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YCx0CknWQAMFSNNHuAxkU0b7ScUE7oVw
"""

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn import metrics
import scipy as sp
from sklearn import preprocessing
from sklearn.model_selection import GridSearchCV
from math import sqrt
from xgboost.sklearn import XGBRegressor

df = pd.read_csv('/content/NFL-DATA.csv')
df = df.dropna()

df = df.drop(['Unnamed: 0', 'Detail', 'name', 'pass_complete', 'other_player'], axis=1)

train = df[df['year'] <= 2018]

test = df[df['year'] == 2019]

train = train.drop(['year'], axis=1)

test = test.drop(['year'], axis=1)

#########################
# Splitting the train set into x and y
#########################

Y_train = train['yards_thrown']

X_train = train.drop(['yards_thrown'], axis=1)

########################
# Splitting the test set into x and y
########################

Y_test = test['yards_thrown']

X_test = test.drop(['yards_thrown'], axis=1)

##########################################
# Random Forest Regressor
##########################################

rfr = RandomForestRegressor(random_state=6, criterion='mse', bootstrap='True',
                            max_depth=10, max_features='auto', 
                            min_samples_leaf=3, min_samples_split=12,n_estimators=500)
print("Random Forest Regressor...")

rfr = rfr.fit(X_train, Y_train)

Y_pred = rfr.predict(X_test)

print("Accuracy:", rfr.score(X_test, Y_test))

rootsqerr = sqrt(mean_squared_error(Y_test,Y_pred))

print("RMSE:",rootsqerr)

####################################
# XGBoostRegressor
####################################

print("XGBoost Regressor...")

xgb1 = XGBRegressor()
parameters = {'nthread':[1,2,3,4], 
              'objective':['reg:linear'],
              'learning_rate': [.03, 0.05, .07], 
              'max_depth': [5, 6, 7],
              'min_child_weight': [4],
              'silent': [1],
              'subsample': [0.7],
              'colsample_bytree': [0.7],
              'n_estimators': [100,200,500]}

xgb_grid = GridSearchCV(xgb1,
                        parameters,
                        cv = 5,
                        n_jobs = 5,
                        verbose=True)

xgb_grid.fit(X_train,Y_train)

print("Best XGB Score:",xgb_grid.best_score_)
print("Best Parameters for XGB:",xgb_grid.best_params_)

import seaborn as sns

dat = pd.read_csv('/content/NFL-DATA.csv')
dat = dat.dropna()
dat = pd.DataFrame(dat)
ab = sns.pairplot(dat, hue ='pass_complete')

ab.savefig("Plot.png")